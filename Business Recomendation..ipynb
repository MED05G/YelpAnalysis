{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "# Analyze check-in patterns\n",
        "checkin_patterns = checkin_df.groupBy(\"date\").count()\n",
        "\n",
        "def generate_business_insights(business_id):\n",
        "    \"\"\"\n",
        "    Generate strategic recommendations using ChatGPT\n",
        "    \"\"\"\n",
        "    checkin_data = checkin_df.filter(\n",
        "        checkin_df.business_id == business_id\n",
        "    ).groupBy(\"hour\").count().toPandas()\n",
        "    \n",
        "    prompt = f\"\"\"\n",
        "    Based on these check-in patterns: {checkin_data.to_dict()},\n",
        "    provide 3 business optimization suggestions for business {business_id}.\n",
        "    \"\"\"\n",
        "    \n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "    #by Mohamed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "from pyspark.sql.functions import lit\n",
        "\n",
        "def get_personalized_recommendations(user_id, latitude=None, longitude=None):\n",
        "    \"\"\"\n",
        "    Combined recommendation system\n",
        "    \"\"\"\n",
        "    # Get collaborative filtering recommendations\n",
        "    cf_recs = model.recommendForUserSubset(\n",
        "        spark.createDataFrame([(user_id,)], [\"user_id\"]), 5\n",
        "    )\n",
        "    \n",
        "    # Get location-based recommendations\n",
        "    if latitude and longitude:\n",
        "        loc_recs = restaurant_df.withColumn(\n",
        "            \"distance\", \n",
        "            calculate_distance(\n",
        "                restaurant_df.latitude, \n",
        "                restaurant_df.longitude, \n",
        "                lit(latitude), \n",
        "                lit(longitude)\n",
        "            )\n",
        "        ).orderBy(\"distance\").limit(5)\n",
        "    \n",
        "    # Combine and return results with ChatGPT explanations\n",
        "    final_recs = []\n",
        "    for rec in cf_recs.take(5):\n",
        "        explanation = generate_recommendation_explanation(user_id, rec.business_id)\n",
        "        final_recs.append({\n",
        "            \"business_id\": rec.business_id,\n",
        "            \"explanation\": explanation\n",
        "        })\n",
        "    \n",
        "\n",
        "    return final_recs\n",
        "\n",
        "    #by Mohamed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.sql.functions import *\n",
        "import os\n",
        "\n",
        "# Initialize Spark with GraphFrames and OOM protection\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"UnifiedRecSys\") \\\n",
        "    .config(\"spark.sql.warehouse.dir\", \"/user/hive/warehouse\") \\\n",
        "    .config(\"spark.executor.memory\", \"4g\") \\\n",
        "    .config(\"spark.driver.memory\", \"4g\") \\\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"50\") \\\n",
        "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
        "    .config(\"spark.jars.packages\", \"graphframes:graphframes:0.8.3-spark3.1-s_2.12\") \\\n",
        "    .enableHiveSupport() \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Import GraphFrame AFTER Spark session is initialized\n",
        "from graphframes import GraphFrame\n",
        "\n",
        "# Configure your custom ChatGPT client\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url='https://xiaoai.plus/v1',\n",
        "    api_key='sk-WvIc4NVMTcUwuqa5xVrHG0VG3V2m2xeAK9Umx0NlDD4ZLPFL'\n",
        ")\n",
        "\n",
        "\n",
        "#by RIDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "# Clean business data\n",
        "business_clean = business_df.filter(\n",
        "    (business_df.categories.isNotNull()) & \n",
        "    (business_df.latitude.isNotNull()) & \n",
        "    (business_df.longitude.isNotNull())\n",
        ")\n",
        "\n",
        "# Create restaurant subset\n",
        "restaurant_categories = [\"American\", \"Mexican\", \"Italian\", \"Japanese\", \"Chinese\"]\n",
        "restaurant_df = business_clean.filter(\n",
        "    business_clean.categories.contains(\"Restaurants\") & \n",
        "    business_clean.categories.rlike(\"|\".join(restaurant_categories))\n",
        ")\n",
        "\n",
        "#by rida "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "from pyspark.ml.recommendation import ALS\n",
        "\n",
        "# Prepare review data\n",
        "als_data = review_df.select(\n",
        "    \"user_id\", \n",
        "    \"business_id\", \n",
        "    review_df.stars.alias(\"rating\")\n",
        ")\n",
        "\n",
        "# Train ALS model\n",
        "als = ALS(\n",
        "    maxIter=5, \n",
        "    regParam=0.01, \n",
        "    userCol=\"user_id\", \n",
        "    itemCol=\"business_id\", \n",
        "    ratingCol=\"rating\"\n",
        ")\n",
        "model = als.fit(als_data)\n",
        "\n",
        "#by rida"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "import openai\n",
        "\n",
        "# Initialize ChatGPT API\n",
        "openai.api_key ='sk-WvIc4NVMTcUwuqa5xVrHG0VG3V2m2xeAK9Umx0NlDD4ZLPFL'\n",
        "\n",
        "def generate_recommendation_explanation(user_id, business_id):\n",
        "    \"\"\"\n",
        "    Generate natural language explanation for recommendations\n",
        "    \"\"\"\n",
        "    business_info = business_df.filter(\n",
        "        business_df.business_id == business_id\n",
        "    ).first()\n",
        "    \n",
        "    prompt = f\"\"\"\n",
        "    Explain why user {user_id} might like {business_info.name}, \n",
        "    a {business_info.categories} business with {business_info.stars} stars, \n",
        "    known for: {business_info.attributes}.\n",
        "    \"\"\"\n",
        "    \n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "    #by aya"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "End"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    },
    "name": "Business Recomendation"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
