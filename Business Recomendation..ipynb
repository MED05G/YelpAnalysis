{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.sql.functions import *\n",
        "import os\n",
        "\n",
        "# Initialize Spark with GraphFrames and OOM protection\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"UnifiedRecSys\") \\\n",
        "    .config(\"spark.sql.warehouse.dir\", \"/user/hive/warehouse\") \\\n",
        "    .config(\"spark.executor.memory\", \"4g\") \\\n",
        "    .config(\"spark.driver.memory\", \"4g\") \\\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"50\") \\\n",
        "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
        "    .config(\"spark.jars.packages\", \"graphframes:graphframes:0.8.3-spark3.1-s_2.12\") \\\n",
        "    .enableHiveSupport() \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Import GraphFrame AFTER Spark session is initialized\n",
        "from graphframes import GraphFrame\n",
        "\n",
        "# Configure your custom ChatGPT client\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url='https://xiaoai.plus/v1',\n",
        "    api_key='sk-WvIc4NVMTcUwuqa5xVrHG0VG3V2m2xeAK9Umx0NlDD4ZLPFL'\n",
        ")\n",
        "\n",
        "\n",
        "#by RIDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "# Clean business data\n",
        "business_clean = business_df.filter(\n",
        "    (business_df.categories.isNotNull()) & \n",
        "    (business_df.latitude.isNotNull()) & \n",
        "    (business_df.longitude.isNotNull())\n",
        ")\n",
        "\n",
        "# Create restaurant subset\n",
        "restaurant_categories = [\"American\", \"Mexican\", \"Italian\", \"Japanese\", \"Chinese\"]\n",
        "restaurant_df = business_clean.filter(\n",
        "    business_clean.categories.contains(\"Restaurants\") & \n",
        "    business_clean.categories.rlike(\"|\".join(restaurant_categories))\n",
        ")\n",
        "\n",
        "#by rida "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "from pyspark.ml.recommendation import ALS\n",
        "\n",
        "# Prepare review data\n",
        "als_data = review_df.select(\n",
        "    \"user_id\", \n",
        "    \"business_id\", \n",
        "    review_df.stars.alias(\"rating\")\n",
        ")\n",
        "\n",
        "# Train ALS model\n",
        "als = ALS(\n",
        "    maxIter=5, \n",
        "    regParam=0.01, \n",
        "    userCol=\"user_id\", \n",
        "    itemCol=\"business_id\", \n",
        "    ratingCol=\"rating\"\n",
        ")\n",
        "model = als.fit(als_data)\n",
        "\n",
        "#by rida"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "End"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    },
    "name": "Business Recomendation"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
